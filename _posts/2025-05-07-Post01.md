---
layout: post
title: What lessons to draw from this study ?
subtitle: "6 - Results"
date: 2025-05-07
cover-img: /assets/img/cover_4.jpg
share-img: /assets/img/cover_4.jpg
tags: [Findings, insightful]
comments: true
mathjax: true
author: Aiza SAKIEVA
---

Our study demonstrates that AI facial recognition algorithms exhibit significant gender and age-based discrimination towards transgender community. The analyzed Caffe-based model consistently misgendered women, with only a small fraction of both cis and trans women correctly identified (9.4% and 20.3%, respectively), while men (both cis and trans) were almost always accurately classified (98% and 100%, respectively). Age estimation was also unreliable, with a pattern of underestimating mean ages but overestimating the upper age limits, and a tendency to age down cis-women but age up trans-women.

These findings reinforce the existing literature on algorithmic bias in facial recognition technologies, which has consistently shown that marginalized groups are more likely to be misclassified due to underrepresentation in training datasets and the persistence of binary gender models. By focusing specifically on the transgender community, we contribute to the empirical research on the intersection of gender and age bias towards transgender people in facial recognition systems. 

The results highlight the urgent need for more inclusive and representative training datasets that account for the diversity of gender identities and age groups, especially given the expanding use of face recognition algorithms. Merely relying on binary gender classification not only erases the experiences of transgender and non-binary individuals but also perpetuates systemic discrimination in real-world applications, from healthcare to law enforcement. Furthermore, it is crucial to address intersectional identities at the crossroads of gender, age, race, and other factors, which are often most vulnerable to misclassification and its consequences. To ensure equitable access and fair treatment, AI developers, policymakers, and industry stakeholders must prioritize the inclusion of gender minorities and other marginalized groups in both data collection and algorithm design.

{: .box-success}
“_We are not what other people say we are. We are who we know ourselves to be, and we are what we love. That's okay._” - Laverne Cox